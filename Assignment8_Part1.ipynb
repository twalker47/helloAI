{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twalker47/helloAI/blob/main/Assignment8_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHKHhVdCYLJx",
        "outputId": "4131f859-ed5c-4d55-ea30-39b8615f3323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.9/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.21.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.1.0)\n",
            "Collecting google-api-core<2dev,>=1.13.0\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (2.17.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from oauth2client->cloud-tpu-client) (4.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.9/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.59.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (5.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.9/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2022.12.7)\n",
            "Installing collected packages: uritemplate, google-api-core, google-api-python-client, cloud-tpu-client\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.0\n",
            "    Uninstalling google-api-core-2.11.0:\n",
            "      Successfully uninstalled google-api-core-2.11.0\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.348 requires google-api-python-client>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloud-tpu-client-0.10 google-api-core-1.34.0 google-api-python-client-1.8.0 uritemplate-3.0.1\n",
            "Looking in indexes: https://pip.repos.neuron.amazonaws.com, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_xla\n",
            "  Using cached https://pip.repos.neuron.amazonaws.com/torch-xla/torch_xla-1.13.0%2Btorchneuron5-cp39-cp39-linux_x86_64.whl (267.6 MB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from torch_xla) (1.4.0)\n",
            "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from torch_xla) (0.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from torch_xla) (6.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.9/dist-packages (from cloud-tpu-client>=0.10.0->torch_xla) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.9/dist-packages (from cloud-tpu-client>=0.10.0->torch_xla) (1.8.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (0.21.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.34.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (0.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.9/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (4.9)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.59.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (5.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.9/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.0.12)\n",
            "Installing collected packages: torch_xla\n",
            "Successfully installed torch_xla-1.13.0+torchneuron5\n"
          ]
        }
      ],
      "source": [
        "# mount google drive here\n",
        "#!pip uninstall torch_xla\n",
        "\n",
        "!pip install --upgrade cloud-tpu-client\n",
        "\n",
        "!pip install -i \"https://pip.repos.neuron.amazonaws.com\" torch_xla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C-O5N3PkmNs",
        "outputId": "1dddefe6-bdd0-4a18-f66f-76d2c01a1d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.347908\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.472815\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.358262\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.300413\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.248143\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.213565\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.401892\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.241117\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.297031\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.193586\n",
            "Test set: Average loss: 0.0024, Accuracy: 9524/10000 (95%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.295638\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.348853\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.055743\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.296754\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.213590\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.109081\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.096402\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.194746\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.158891\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.270151\n",
            "Test set: Average loss: 0.0014, Accuracy: 9710/10000 (97%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create and train a pytorch digit classifier\n",
        "# source: chatgpt with the prompt \"create a pytorch mnist digit classifier\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os\n",
        "os.makedirs(os.path.dirname(PATH), exist_ok=True)\n",
        "\n",
        "# Set a flag to indicate whether we are (re)-training the model\n",
        "# or loading an already trained model\n",
        "PATH = \"/content/drive/MyDrive/models/classifier-digits.pt\"\n",
        "#loadmodel = False\n",
        "\n",
        "# Set device to either CUDA or CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))\n",
        "        x = nn.functional.relu(nn.functional.max_pool2d(self.dropout(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "if loadmodel:\n",
        "  model = Net()\n",
        "  model.load_state_dict(torch.load(PATH))\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "else:\n",
        "  # Create an instance of the model and send it to the device\n",
        "  model = Net().to(device)\n",
        "\n",
        "  # Load the MNIST dataset and apply transformations\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.1307,), (0.3081,))\n",
        "  ])\n",
        "\n",
        "  train_set = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "  test_set = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
        "\n",
        "  # Set batch size and create data loaders\n",
        "  batch_size = 64\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "  # Define the optimizer and loss function\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Train the model\n",
        "  num_epochs = 2\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if batch_idx % 100 == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "      model.eval()\n",
        "      test_loss = 0\n",
        "      correct = 0\n",
        "      with torch.no_grad():\n",
        "          for data, target in test_loader:\n",
        "              data, target = data.to(device), target.to(device)\n",
        "              output = model(data)\n",
        "              test_loss += criterion(output, target).item()\n",
        "              pred = output.argmax(dim=1, keepdim=True)\n",
        "              correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "      test_loss /= len(test_loader.dataset)\n",
        "      print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          test_loss, correct, len(test_loader.dataset),\n",
        "          100. * correct / len(test_loader.dataset)))  \n",
        "\n",
        "  torch.save(model.state_dict(), PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "IbfEWQ-Ft9S3",
        "outputId": "d3382061-3144-4483-db74-597cb719439a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e8509017e619>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;31m# Move the generator and discriminator networks to the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m   \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m   \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PyTorch is not linked with support for xla devices"
          ]
        }
      ],
      "source": [
        "#OK now we have a good model for analyzing the output from our GAN\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "\n",
        "# flag for saving/loading\n",
        "PATH_G = \"/content/drive/MyDrive/models/generator-digits.pt\"\n",
        "PATH_D = \"/content/drive/MyDrive/models/discriminator-digits.pt\"\n",
        "loadgan = False\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(100, 7 * 7 * 128)\n",
        "        self.conv1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 128, 7, 7)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.tanh(self.conv2(x))\n",
        "        return x\n",
        "\n",
        "# Define the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.fc = nn.Linear(7 * 7 * 128, 1)\n",
        "\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = x.view(-1, 7 * 7 * 128)\n",
        "        x = self.sigmoid(self.fc(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate the generator and discriminator networks\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if loadgan:\n",
        "  generator.load_state_dict(torch.load(PATH_G))\n",
        "  generator = generator.to(device)\n",
        "  generator.eval()\n",
        "  discriminator.load_state_dict(torch.load(PATH_D))\n",
        "  discriminator = discriminator.to(device)\n",
        "  discriminator.eval()\n",
        "\n",
        "else:\n",
        "  # Define the loss function and optimizer\n",
        "  criterion = nn.BCELoss()\n",
        "  generator_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "  discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "  # Load the dataset\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5,), (0.5,))\n",
        "  ])\n",
        "  dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "  dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "  # Define the number of epochs and the device to use\n",
        "  num_epochs = 10\n",
        "  device = torch.device('xla')\n",
        "\n",
        "  # Move the generator and discriminator networks to the device\n",
        "  generator.to(device)\n",
        "  discriminator.to(device)\n",
        "\n",
        "  # Train the generator and discriminator networks\n",
        "  time_total = 0\n",
        "  d_losses = []\n",
        "  g_losses = []\n",
        "  counts = [0]*10\n",
        "  confidences = []\n",
        "  for epoch in range(num_epochs):\n",
        "      time_epoch = 0\n",
        "      start = time.time()\n",
        "      for i, (real_images, _) in enumerate(dataloader):\n",
        "          batch_size = real_images.shape[0]\n",
        "          real_labels = torch.ones(batch_size, 1, device=device)\n",
        "          fake_labels = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "          # Train the discriminator network\n",
        "          discriminator_optimizer.zero_grad()\n",
        "          real_images = real_images.to(device)\n",
        "          real_outputs = discriminator(real_images)\n",
        "          real_loss = criterion(real_outputs, real_labels)\n",
        "\n",
        "          noise = torch.randn(batch_size, 100, device=device)\n",
        "          fake_images = generator(noise)\n",
        "          fake_outputs = discriminator(fake_images.detach())\n",
        "          fake_loss = criterion(fake_outputs, fake_labels)\n",
        "\n",
        "          discriminator_loss = real_loss + fake_loss\n",
        "          discriminator_loss.backward()\n",
        "          discriminator_optimizer.step()\n",
        "\n",
        "          # Train the generator network\n",
        "          generator_optimizer.zero_grad()\n",
        "          noise = torch.randn(batch_size, 100, device=device)\n",
        "          fake_images = generator(noise)\n",
        "          fake_outputs = discriminator(fake_images)\n",
        "          generator_loss = criterion(fake_outputs, real_labels)\n",
        "          generator_loss.backward()\n",
        "          generator_optimizer.step()\n",
        "\n",
        "          # Print the loss statistics\n",
        "          if i % 100 == 0:\n",
        "              print(f'Epoch [{epoch+1}/{num_epochs}] Batch [{i+1}/{len(dataloader)}] '\n",
        "                    f'Discriminator Loss: {discriminator_loss.item():.4f} '\n",
        "                    f'Generator Loss: {generator_loss.item():.4f}')\n",
        "\n",
        "      # Generate 100 samples and count how many of each digit \n",
        "      with torch.no_grad():\n",
        "          # Define the fixed noise vector for generating samples\n",
        "          sample_noise = torch.randn(100, 100, device=device)\n",
        "          generated_images = generator(sample_noise)\n",
        "          generated_images = 0.5 * (generated_images + 1)\n",
        "          output = model(generated_images)\n",
        "          pred = output.argmax(dim=1, keepdim=True)\n",
        "          grid = make_grid(generated_images[:16].cpu(), nrow=8, pad_value=1)\n",
        "          plt.imshow(grid.permute(1, 2, 0))\n",
        "          plt.axis('off')\n",
        "          plt.title([int(pred[x]) for x in range(16)])\n",
        "          plt.show()\n",
        "          #print(torch.exp(output[0])) # torch.exp converts the output back into regular softmax probabilities (confidences)\n",
        "          avg_conf = torch.mean(torch.exp(output).max(dim=1).values)\n",
        "          confidences.append(avg_conf)\n",
        "          for p in pred:\n",
        "              counts[p] += 1\n",
        "\n",
        "      g_losses.append(generator_loss.item())\n",
        "      d_losses.append(discriminator_loss.item())\n",
        "      time_epoch = time.time() - start\n",
        "      time_total += time_epoch\n",
        "      print(f\"average prediction confidence over 100 predictions: {avg_conf}\")\n",
        "      print(f\"prediction counts: {counts}\")\n",
        "      print(f\"epoch time: {time_epoch}, total time: {time_total}\")\n",
        "        \n",
        "      torch.save(generator.state_dict(), PATH_G)\n",
        "      torch.save(discriminator.state_dict(), PATH_D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "GtOxAvQqT9g7",
        "outputId": "6a812346-345b-4866-aa17-d9cfcf6597bc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-dc81369616ac>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "  # Check if CUDA is available, otherwise use CPU\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  # Define the fixed noise vector for generating samples\n",
        "  sample_noise = torch.randn(100, 100, device=device)\n",
        "  generated_images = generator(sample_noise)\n",
        "  generated_images = 0.5 * (generated_images + 1)\n",
        "  output = model(generated_images)\n",
        "  pred = output.argmax(dim=1, keepdim=True)\n",
        "  grid = make_grid(generated_images[:16].cpu(), nrow=8, pad_value=1)\n",
        "  plt.imshow(grid.permute(1, 2, 0))\n",
        "  plt.axis('off')\n",
        "  plt.title([int(pred[x]) for x in range(16)])\n",
        "  plt.show()\n",
        "  #print(torch.exp(output[0])) # torch.exp converts th\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J_EYSdCAMVlO",
        "outputId": "51c95b51-ffbd-45a9-957d-d19d720f9a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-017456d5a036>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfidences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"x\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'confidences' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(confidences)\n",
        "plt.show()\n",
        "plt.bar([f\"x\" for x in range(10)], counts)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(100, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 28*28)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = nn.functional.tanh(self.fc3(x))\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        return x\n",
        "\n",
        "# Define the classifier network\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))\n",
        "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "# Initialize the generator and classifier networks\n",
        "generator = Generator().to('cuda')\n",
        "classifier = Classifier().to('cuda')\n",
        "\n",
        "# Load the MNIST dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define the optimizer and loss function for training the classifier\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Train the classifier for 5 epochs\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to('cuda'), data[1].to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = classifier(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Generate 100 images using the generator and classify them using the classifier\n",
        "    with torch.no_grad():\n",
        "        sample_noise = torch.randn(100, 100, device='cuda')\n",
        "        generated_images = generator(sample_noise)\n",
        "        generated_images = 0.5 * (generated_images + 1)\n",
        "        output = classifier(generated_images)\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "        # Count how many of each digit are generated\n",
        "        counts = torch.zeros(10)\n",
        "        for p in pred:\n",
        "            counts[p.item()] += 1\n",
        "\n",
        "        # Calculate the average prediction confidence\n",
        "        avg_confidence = torch.exp(output).mean()\n",
        "\n",
        "        # Spot-check several generated samples to see if they were\n"
      ],
      "metadata": {
        "id": "k8t_ryEEnP2e",
        "outputId": "0a1a8de9-691f-4ff6-dfa9-aa2c72546bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cac26506b06a>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Initialize the generator and classifier networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}